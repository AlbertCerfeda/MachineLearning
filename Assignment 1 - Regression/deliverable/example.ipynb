{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GiorgiaAuroraAdorni/ML-bachelor-course-assignments-sp23/blob/main/assignment%201/deliverable/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "Student: Albert Cerfeda\n",
    "\n",
    "--- \n",
    "# IMPORTANT: all the submitted code should be in 2 cells\n",
    "1) How you trained, evaluated and saved your model\n",
    "2) How to load your model from a file, load the data and evaluate the model. Cell 2) should be running independently (even if cell 1 is not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # Library for plotting\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import joblib\n",
    "\n",
    "# Load data \n",
    "data = np.load('../data/data.npz')\n",
    "\n",
    "x = data.f.x\n",
    "y = data.f.y.reshape(-1,1)\n",
    "\n",
    "\n",
    "# T1 : Solving using sklearn.LinearRegression()\n",
    "# Split data into training data and test data\n",
    "# 0.7 means 70% of the data is used for training and 30% for testing\n",
    "# We shuffle the data to grant the independetly and identically distributed properties of the data\n",
    "train, test = train_test_split(np.hstack((x,y)), train_size=0.7, shuffle=True, random_state=0)\n",
    "\n",
    "# We normalize the features around their mean and standard deviation\n",
    "train = (train- train.mean(0)) / train.std(0)\n",
    "test = (test- test.mean(0)) / test.std(0)\n",
    "\n",
    "x_train = train[:, 0:2] \n",
    "y_train = train[:, -1] # The last row (the 3rd) is the feature we are trying to predict\n",
    "x_test  = test[:, 0:2]\n",
    "y_test  = test[:, -1]\n",
    "\n",
    "# 2 features - 5 parameters\n",
    "def compact_form(x):\n",
    "    ones_vector = np.ones((x.shape[0],1))\n",
    "    x = x.reshape(-1,2)\n",
    "    return np.hstack((ones_vector, x[:,0].reshape(-1,1), x[:,1].reshape(-1,1), np.sin(x[:,1]).reshape(-1,1), (x[:,0]*x[:,1]).reshape(-1,1)))#.reshape(-1,5)\n",
    "\n",
    "x_train_compact = compact_form(x_train)\n",
    "x_test_compact = compact_form(x_test)\n",
    "## Solving using sklearn.LinearRegression()\n",
    "t1_d_linear_model = LinearRegression(fit_intercept=False)\n",
    "t1_d_linear_model.fit(x_train_compact, y_train)\n",
    "t1_theta = t1_d_linear_model.coef_.T\n",
    "### Measure performance\n",
    "#### Train set\n",
    "t1_y_train_pred = t1_d_linear_model.predict(x_train_compact)\n",
    "t1_y_train_mse = mean_squared_error(t1_y_train_pred, y_train)\n",
    "#### Test set\n",
    "t1_y_test_pred = t1_d_linear_model.predict(x_test_compact)\n",
    "t1_y_test_mse = mean_squared_error(t1_y_test_pred, y_test)\n",
    "\n",
    "## Printing / plotting ecc\n",
    "print('train.shape :', train.shape)\n",
    "print('test.shape :', test.shape)\n",
    "print(\"\\n\\n== T1. LINEAR REGRESSION ==\")\n",
    "print(f\"MSE Train set:\\t{t1_y_train_mse:.4f}\")\n",
    "print(f\"MSE Test set:\\t{t1_y_test_mse:.4f}\")\n",
    "print(f\"Optimal theta:\\t{t1_theta}\")\n",
    "# plot results\n",
    "fig = plt.figure()\n",
    "interval = np.linspace(0, 2, 1000).reshape(1000,1)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(x_test[:,0], x_test[:,1], y_test, label=\"y\")\n",
    "ax.scatter3D(x_test[:,0], x_test[:,1], t1_y_test_pred, label=\"prediction\")\n",
    "plt.title('Linear Regression\\nMSE: {:.4f}'.format(t1_y_test_mse))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('out/T1.predictions.png', bbox_inches='tight')\n",
    "for i in range((len(t1_theta))):\n",
    "    f = open(f\"out/T1_theta_{i}.tex\", \"w\")\n",
    "    f.write(f\"{t1_theta[i]:.5f}\")\n",
    "    f.close()\n",
    "f = open(\"out/T1_MSE_Train.tex\", \"w\")\n",
    "f.write(f\"{t1_y_train_mse:.5f}\")\n",
    "f.close()\n",
    "f = open(\"out/T1_MSE_Test.tex\", \"w\")\n",
    "f.write(f\"{t1_y_test_mse:.5f}\")\n",
    "f.close()\n",
    "\n",
    "pickle.dump(t1_d_linear_model, open(\"./out/model_T1_linear.pickle\", 'wb'))\n",
    "\n",
    "######################################\n",
    "######################################\n",
    "\n",
    "# T2 : Solving using PolynomialFeatures and Ridge regression\n",
    "# Fit a polynomial of degree 7 to the data\n",
    "pol_feat_high = PolynomialFeatures(degree=7, include_bias=False)\n",
    "x_train_compact_polynomial = pol_feat_high.fit_transform(x_train_compact)\n",
    "x_test_compact_polynomial = pol_feat_high.transform(x_test_compact)\n",
    "\n",
    "# Ridge regression\n",
    "t2_model = Ridge(alpha=1, fit_intercept=True)\n",
    "t2_model.fit(x_train_compact_polynomial, y_train)\n",
    "t2_theta = t2_model.coef_.T\n",
    "\n",
    "### Measure performance\n",
    "#### Train set\n",
    "t2_y_train_pred = t2_model.predict(x_train_compact_polynomial)\n",
    "t2_y_train_mse = mean_squared_error(t2_y_train_pred, y_train)\n",
    "#### Test set\n",
    "t2_y_test_pred = t2_model.predict(x_test_compact_polynomial)\n",
    "t2_y_test_mse = mean_squared_error(t2_y_test_pred, y_test)\n",
    "\n",
    "\n",
    "## Printing / plotting ecc\n",
    "print('x_train_compact_polynomial.shape :', x_train_compact_polynomial.shape)\n",
    "print('x_train_compact.shape:', x_train_compact.shape)\n",
    "print(\"\\n== T2. Ridge ==\")\n",
    "print(f\"MSE Train set:\\t{t2_y_train_mse:.2f}\")\n",
    "print(f\"MSE Test set:\\t{t2_y_test_mse:.2f}\")\n",
    "# plot results\n",
    "fig = plt.figure()\n",
    "interval = np.linspace(0,2,1000).reshape(1000,1)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(x_test[:,0], x_test[:,1], y_test, label=\"y\")\n",
    "ax.scatter3D(x_test[:,0], x_test[:,1], t2_y_test_pred, label=\"prediction\")\n",
    "plt.title('Ridge regression\\nMSE: {:.4f}'.format(t2_y_test_mse))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('out/T2.predictions.png', bbox_inches='tight')\n",
    "f = open(\"out/T2_MSE_Train.tex\", \"w\")\n",
    "f.write(f\"{t2_y_train_mse:.5f}\")\n",
    "f.close()\n",
    "f = open(\"out/T2_MSE_Test.tex\", \"w\")\n",
    "f.write(f\"{t2_y_test_mse:.5f}\")\n",
    "f.close()\n",
    "\n",
    "pickle.dump(t2_model, open(\"./out/model_T2_ridge.pickle\", 'wb'))\n",
    "\n",
    "# T3 (Bonus) : Neural Network\n",
    "t3_NN = Sequential()\n",
    "t3_NN.add(Dense(64, activation='elu', input_dim = 2))\n",
    "t3_NN.add(Dense(64, activation='relu'))\n",
    "t3_NN.add(Dense(64, activation='sigmoid'))\n",
    "t3_NN.add(Dense(1, activation='linear'))\n",
    "t3_NN.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "t3_x_train, t3_x_val, t3_y_train, t3_y_val = train_test_split(x_train, y_train, train_size=0.7, shuffle=True, random_state=0)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)\n",
    " \n",
    "t3_NN.fit(t3_x_train, t3_y_train, epochs=1000, validation_data=(t3_x_val, t3_y_val), callbacks=[early_stop])\n",
    "# Get the thetas\n",
    "t3_theta = t3_NN.get_weights()\n",
    "\n",
    "### Measure performance\n",
    "#### Train set\n",
    "t3_y_train_pred = t3_NN.predict(t3_x_train)\n",
    "t3_y_train_mse = mean_squared_error(t3_y_train_pred, t3_y_train)\n",
    "#### Test set\n",
    "t3_y_test_pred = t3_NN.predict(x_test)\n",
    "t3_y_test_mse = mean_squared_error(t3_y_test_pred, y_test)\n",
    "\n",
    "\n",
    "## Printing / plotting ecc\n",
    "print(\"\\n== T3. NN ==\")\n",
    "print(f\"MSE Train set:\\t{t3_y_train_mse:.4f}\")\n",
    "print(f\"MSE Test set:\\t{t3_y_test_mse:.4f}\")\n",
    "# print(f\"Optimal theta:\\t{t2_theta}\")\n",
    "# plot results\n",
    "fig = plt.figure()\n",
    "interval = np.linspace(0, 2, 1000).reshape(1000,1)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(x_test[:,0], x_test[:,1], y_test, label=\"y\")\n",
    "ax.scatter3D(x_test[:,0], x_test[:,1], t3_y_test_pred, label=\"prediction\")\n",
    "plt.title('NN\\nMSE: {:.4f}'.format(t3_y_test_mse))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('out/T3.predictions.png', bbox_inches='tight')\n",
    "f = open(\"out/T3_MSE_Train.tex\", \"w\")\n",
    "f.write(f\"{t3_y_train_mse:.5f}\")\n",
    "f.close()\n",
    "f = open(\"out/T3_MSE_Test.tex\", \"w\")\n",
    "f.write(f\"{t3_y_test_mse:.5f}\")\n",
    "f.close()\n",
    "\n",
    "joblib.dump(t3_NN, \"./out/model_T3_NN.pickle\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example on how to use baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== T1. Linear ==\n",
      "MSE:\t0.4812\n",
      "\n",
      "== T2. Ridge ==\n",
      "MSE:\t0.0575\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMSE:\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mt2_y_mse\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[39m# T3\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m t3_y_pred \u001b[39m=\u001b[39m model3\u001b[39m.\u001b[39mpredict(x_compact)\n\u001b[1;32m     93\u001b[0m t3_y_mse \u001b[39m=\u001b[39m mean_squared_error(t3_y_pred, y)\n\u001b[1;32m     94\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m== T3. NN ==\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import joblib\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluates the mean squared error between the values in y_true and the values\n",
    "    in y_pred.\n",
    "    ### YOU CAN NOT EDIT THIS FUNCTION ###\n",
    "    :param y_true: Numpy array, the true target values from the test set;\n",
    "    :param y_pred: Numpy array, the values predicted by your model.\n",
    "    :return: float, the mean squared error between the two arrays.\n",
    "    \"\"\"\n",
    "    print(y_true.shape, y_pred.shape)\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Loads a Scikit-learn model saved with joblib.dump.\n",
    "    This is just an example, you can write your own function to load the model.\n",
    "    Some examples can be found in src/utils.py.\n",
    "    :param filename: string, path to the file storing the model.\n",
    "    :return: the model.\n",
    "    \"\"\"\n",
    "    model = joblib.load(filename)\n",
    "    return model\n",
    "\n",
    "def compact_form(x):\n",
    "    ones_vector = np.ones((x.shape[0],1))\n",
    "    x = x.reshape(-1,2)\n",
    "    return np.hstack((ones_vector, x[:,0].reshape(-1,1), x[:,1].reshape(-1,1), np.sin(x[:,1]).reshape(-1,1), (x[:,0]*x[:,1]).reshape(-1,1)))#.reshape(-1,5)\n",
    "\n",
    "# Load the data\n",
    "# This will be replaced with our private test data when grading the assignment\n",
    "\n",
    "# Load data from url\n",
    "# url = 'https://drive.switch.ch/index.php/s/TeDwnbYsBKRuJjv/download'\n",
    "# response = requests.get(url)\n",
    "# data = np.load(io.BytesIO(response.content))\n",
    "\n",
    "# Alternatively yo can load the data from file\n",
    "data_path = '../data/data.npz'\n",
    "data = np.load(data_path)\n",
    "\n",
    "# Load the trained model\n",
    "model0 = load_model(\"./baseline_model.pickle\")\n",
    "model1 = pickle.load(open(\"./out/model_T1_linear.pickle\", 'rb'))\n",
    "model2 = pickle.load(open(\"./out/model_T2_ridge.pickle\", 'rb'))\n",
    "# model3 = load_mod el(\"./out/model_T3_NN.pickle\")\n",
    "\n",
    "\n",
    "# x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
    "x = data.f.x\n",
    "# y is a Numpy array of shape (n_samples, ) with the targets\n",
    "y = data.f.y.reshape(-1,1)\n",
    "train, test = train_test_split(np.hstack((x,y)), train_size=0.7, shuffle=True, random_state=0)\n",
    "train = (train- train.mean(0)) / train.std(0)\n",
    "test = (test- test.mean(0)) / test.std(0)\n",
    "x_train = train[:, 0:2] \n",
    "y_train = train[:, -1]\n",
    "x_test  = test[:, 0:2]\n",
    "y_test  = test[:, -1]\n",
    "\n",
    "# Will be used for evaluation\n",
    "x = x_test \n",
    "y = y_test\n",
    "x_compact = compact_form(x)\n",
    "pol_feat_high = PolynomialFeatures(degree=7, include_bias=False)\n",
    "x_compact_polynomial = pol_feat_high.fit_transform(x_compact)\n",
    "\n",
    "# T1\n",
    "t1_y_pred = model1.predict(x_compact)\n",
    "t1_y_mse = mean_squared_error(t1_y_pred, y)\n",
    "print(\"== T1. Linear ==\")\n",
    "print(f\"MSE:\\t{t1_y_mse:.4f}\")\n",
    "\n",
    "# T2\n",
    "t2_y_pred = model2.predict(x_compact_polynomial)\n",
    "t2_y_mse = mean_squared_error(t2_y_pred, y)\n",
    "print(\"\\n== T2. Ridge ==\")\n",
    "print(f\"MSE:\\t{t2_y_mse:.4f}\")\n",
    "\n",
    "# T3\n",
    "t3_y_pred = model3.predict(x_compact)\n",
    "t3_y_mse = mean_squared_error(t3_y_pred, y)\n",
    "print(\"\\n== T3. NN ==\")\n",
    "print(f\"MSE:\\t{t3_y_mse:.4f}\")\n",
    "\n",
    "\n",
    "# Choose a set of predicted values from any model\n",
    "y_pred = t1_y_pred\n",
    "# y_pred = t2_y_pred\n",
    "# y_pred = t3_y_pred\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# STOP EDITABLE SECTION: do not modify anything below this point.\n",
    "############################################################################\n",
    "\n",
    "# Evaluate the prediction using MSE\n",
    "mse = evaluate_predictions(y_pred, y)\n",
    "print(f'MSE on whole dataset: {mse}')\n",
    "\n",
    "# NOTE: NOW THIS CELL IS NOT WORKING SINCE YOU NEED TO CHANGE THE INPUT.\n",
    "# DO IT AND EVERYTHING RUNS SMOOTH\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
